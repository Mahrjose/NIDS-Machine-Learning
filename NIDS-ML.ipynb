{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeDataSet = './data/raw/KDDTrain.arff'\n",
    "smallDataSet = './data/raw/KDDTrain_20Percent.arff'\n",
    "\n",
    "largeTestData = './data/raw/KDDTest.arff'\n",
    "smallTestData = './data/raw/KDDTest-21.arff'\n",
    "\n",
    "# Loading the .arff data format into a pandas dataframe\n",
    "data, meta = arff.loadarff(smallDataSet)\n",
    "test_data, test_meta = arff.loadarff(smallTestData)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Review of the dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Infomaion\n",
    "- Dataset: NSL-KDD\n",
    "- Source: https://www.kaggle.com/datasets/hassan06/nslkdd\n",
    "\n",
    "- Description: The dataset is a modified version of the NSL-KDD dataset, which is a subset of the original KDD'99 dataset. The number of records in the NSL-KDD train and test sets are 125,973 and 22,544 respectively. These were created by applying the following two steps to the original dataset:\n",
    "    - Duplicate free: The duplicate records were removed from the original KDD'99 dataset.\n",
    "    - Binary: The multiclass attacks in the dataset were converted to binary by combining all the attack types into a single attack type, and the normal records remained unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of features and samples and values types in the dataset\n",
    "features = df.shape[1]\n",
    "samples = df.shape[0]\n",
    "value_types = ', '.join(df.dtypes.unique().astype(str))\n",
    "\n",
    "# Print the information\n",
    "print('Dataset Information: ')\n",
    "print('--------------------')\n",
    "print(f\"Dataset has {features} features and {samples} samples.\")\n",
    "print(f\"Dataset Value types: {value_types}\")\n",
    "print(f\"Dataset has {df.isnull().sum().sum()} missing values.\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Dataset summary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning : Handling & Imputing Missing Values\n",
    "\n",
    "In this stage we're ensuring there's no missing / null values in the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Checking if data include missing values\n",
    "missingValues = df.isnull().sum()\n",
    "print(f\"Missing Values in every Column: \\n{missingValues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Anomolies in the dataset\n",
    "print(f\"Descriptive Statistics: \\n{df.describe(include='all')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's no missing values in the dataset, we don't need to handle/ impute missing values.\n",
    "Also, since every feature is complete with its values, we don't need to drop any feature.\n",
    "\n",
    "## Outliers and Removing the Outliers\n",
    "We'll find the outliers in the dataset and remove them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pair plot with 'hue' parameter for coloring based on the 'class' column\n",
    "# sns.pairplot(df[[\"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"class\"]], hue='class', diag_kind='kde')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as there is outliers in our dataset, we will remove them. We will use the Z-score method to detect and remove the outliers. The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# A threshold value beyod which a data point is considered as an outlier\n",
    "zscore_threshold = 3\n",
    "\n",
    "# Calculate Z-scores for numeric columns (excluding categorical)\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "z_scores = np.abs(zscore(df[numeric_columns]))\n",
    "\n",
    "# Create a outlier mask indicating whether each row is an outlier or not\n",
    "outlier_mask = np.any(z_scores > zscore_threshold, axis=1)\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "df_original = df.copy()\n",
    "df = df_original[~outlier_mask]\n",
    "\n",
    "# Display the shape before and after removing outliers\n",
    "print(\"Dataset Shape before removing outliers:\", df_original.shape)\n",
    "print(\"Dataset Shape after removing outliers:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for numeric columns in the test data (excluding categorical)\n",
    "numeric_columns_test = df_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "z_scores_test = np.abs(zscore(df_test[numeric_columns_test]))\n",
    "\n",
    "# Create an outlier mask for the test data indicating whether each row is an outlier or not\n",
    "outlier_mask_test = np.any(z_scores_test > zscore_threshold, axis=1)\n",
    "\n",
    "# Remove outliers from the test dataset\n",
    "df_test_original = df_test.copy()\n",
    "df_test = df_test_original[~outlier_mask_test]\n",
    "\n",
    "# Display the shape before and after removing outliers from the test dataset\n",
    "print(\"Test Dataset Shape before removing outliers:\", df_test_original.shape)\n",
    "print(\"Test Dataset Shape after removing outliers:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "After removing the outliers, We'll now scale our datasets. We'll consider using both MinmaxScaler and StandardScaler to see which one performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()[:-1]  # Exclude the target\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoded_columns = pd.get_dummies(df[categorical_columns], drop_first=True)\n",
    "\n",
    "# Scale numeric columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_columns = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Scale numeric columns using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaled_columns = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Convert the scaled numeric columns back to a DataFrame with appropriate column names\n",
    "# Combine scaled numeric columns with the one-hot encoded categorical columns\n",
    "# Note: Here, we're using the original index from the DataFrame 'df' to ensure alignment\n",
    "scaled_df = pd.DataFrame(scaled_columns, columns=numeric_columns, index=df.index)\n",
    "df_scaled = pd.concat([scaled_df, encoded_columns], axis=1)\n",
    "\n",
    "df_not_scaled = df.copy()\n",
    "df = df_scaled\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "categorical_columns = df_test.select_dtypes(include=['object']).columns.tolist()[:-1]  # Exclude the target\n",
    "numeric_columns = df_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoded_columns = pd.get_dummies(df_test[categorical_columns], drop_first=True)\n",
    "\n",
    "# Scale numeric columns using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_columns = scaler.fit_transform(df_test[numeric_columns])\n",
    "\n",
    "# Scale numeric columns using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaled_columns = scaler.fit_transform(df_test[numeric_columns])\n",
    "\n",
    "# Convert the scaled numeric columns back to a DataFrame with appropriate column names\n",
    "# Combine scaled numeric columns with the one-hot encoded categorical columns\n",
    "# Note: Here, we're using the original index from the DataFrame 'df' to ensure alignment\n",
    "scaled_df_test = pd.DataFrame(scaled_columns, columns=numeric_columns, index=df_test.index)\n",
    "df_test_scaled = pd.concat([scaled_df_test, encoded_columns], axis=1)\n",
    "\n",
    "df_test_not_scaled = df_test.copy()\n",
    "df_test = df_test_scaled\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correletion analysis -\n",
    "feature seletion - \n",
    "hadling class imbalance -\n",
    "dimentionality reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correletion Analysis\n",
    "We'll use the Pearson Correlation method to find the correlation between the features. We'll remove the features which are highly correlated with each other. We'll try to keep the features which are highly correlated with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficients\n",
    "correlation_matrix = df.corr(method='pearson')\n",
    "\n",
    "# Set up the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(style=\"white\")\n",
    "cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "\n",
    "# Create the heatmap without annotations\n",
    "ax = sns.heatmap(correlation_matrix, cmap=cmap, annot=False, fmt=\".2f\", square=True, center=0, linewidths=0.5)\n",
    "\n",
    "# Set x-axis and y-axis labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, verticalalignment='center')\n",
    "\n",
    "# Show colorbar with correlation scale\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_label('Correlation Strength')\n",
    "\n",
    "plt.title(\"Pearson Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficients\n",
    "correlation_matrix = df_test.corr(method='pearson')\n",
    "\n",
    "# Set up the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(style=\"white\")\n",
    "cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "\n",
    "# Create the heatmap without annotations\n",
    "ax = sns.heatmap(correlation_matrix, cmap=cmap, annot=False, fmt=\".2f\", square=True, center=0, linewidths=0.5)\n",
    "\n",
    "# Set x-axis and y-axis labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, verticalalignment='center')\n",
    "\n",
    "# Show colorbar with correlation scale\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_label('Correlation Strength')\n",
    "\n",
    "plt.title(\"Pearson Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We'll remove some features that are not useful for our model. We'll remove the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove From test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Reduction\n",
    "We'll use PCA to reduce the dimensionality of our dataset. We'll use the elbow method to determine the number of components to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Since our current dataframe doesn't include our target class we don't need to drop it\n",
    "# X = df.drop(\"target_column_name\", axis=1)\n",
    "unprocessed = df\n",
    "\n",
    "# Initializing PCA with the number features to keep\n",
    "feature_to_keep = 75\n",
    "pca = PCA(n_components=feature_to_keep)\n",
    "\n",
    "# Fitting PCA on data\n",
    "preprocessed = pca.fit_transform(unprocessed)\n",
    "\n",
    "print(f'Original shape: {unprocessed.shape}\\nafter PCA: {preprocessed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since our current dataframe doesn't include our target class we don't need to drop it\n",
    "# X = df.drop(\"target_column_name\", axis=1)\n",
    "unprocessed_test = df_test\n",
    "\n",
    "# Initializing PCA with the number features to keep\n",
    "feature_to_keep_test = 75\n",
    "pca_test = PCA(n_components=feature_to_keep)\n",
    "\n",
    "# Fitting PCA on data\n",
    "preprocessed_test = pca_test.fit_transform(unprocessed_test)\n",
    "\n",
    "print(f'Original Test shape: {unprocessed_test.shape}\\nafter PCA: {preprocessed_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "Now, we will split the data into training and testing sets. We will use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "target = df_not_scaled['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the split datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "We'll start by training a Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Binary Encoding the class variable for Naive-Bayes\n",
    "# then splitting the data into trainning and testing sets\n",
    "df_not_scaled['class'] = df_not_scaled['class'].apply(lambda x: 0 if x == b'normal' else 1)\n",
    "\n",
    "target = df_not_scaled['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize the Naive Bayes model and trainning the model\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model and calculating the accuracy of the model\n",
    "# and calculating the confusing matrix\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred, target_names=[\"normal\", \"attack\"])\n",
    "\n",
    "print(\"================= Naive-Bayes Classifier=================\\n\")\n",
    "\n",
    "print(f\"Accuracy of Naive Bayes Classifier: {accuracy*100:.2f}%\\n\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Binary Encoding the class variable for Naive-Bayes\n",
    "df_test_not_scaled['class'] = df_test_not_scaled['class'].apply(lambda x: 0 if x == b'normal' else 1)\n",
    "\n",
    "# Splitting the data into training and testing sets for testing\n",
    "target_test = df_test_not_scaled['class']\n",
    "X_test_final = preprocessed_test\n",
    "y_test_final = target_test\n",
    "\n",
    "# Initialize the Naive Bayes model and train it on the training data\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model on the preprocessed test data and calculating the accuracy\n",
    "y_pred_test = naive_bayes_model.predict(X_test_final)\n",
    "accuracy_test = accuracy_score(y_test_final, y_pred_test)\n",
    "\n",
    "# Calculating the confusion matrix, precision, recall, and F1-score\n",
    "conf_matrix_test = confusion_matrix(y_test_final, y_pred_test)\n",
    "report_test = classification_report(y_test_final, y_pred_test, target_names=[\"normal\", \"attack\"])\n",
    "\n",
    "print(\"================= Naive-Bayes Classifier - Test Data =================\\n\")\n",
    "print(f\"Accuracy of Naive Bayes Classifier on Test Data: {accuracy_test*100:.2f}%\\n\")\n",
    "print(f\"Confusion Matrix on Test Data:\")\n",
    "print(conf_matrix_test)\n",
    "print()\n",
    "print(\"Classification Report on Test Data:\")\n",
    "print(report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN model and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model and calculating the accuracy of the model\n",
    "# and calculating the confusion matrix\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred, target_names=[\"normal\", \"attack\"])\n",
    "\n",
    "print(\"================= K-Nearest Neighbors (KNN) Classifier =================\\n\")\n",
    "\n",
    "print(f\"Accuracy of KNN Classifier: {accuracy*100:.2f}%\\n\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Initialize the KNN model and train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the KNN model on the preprocessed test data and calculating the accuracy\n",
    "y_pred_test = knn_model.predict(X_test_final)\n",
    "accuracy_test = accuracy_score(y_test_final, y_pred_test)\n",
    "\n",
    "# Calculating the confusion matrix, precision, recall, and F1-score\n",
    "conf_matrix_test = confusion_matrix(y_test_final, y_pred_test)\n",
    "report_test = classification_report(y_test_final, y_pred_test, target_names=[\"normal\", \"attack\"])\n",
    "\n",
    "print(\"================= K-Nearest Neighbors (KNN) Classifier - Test Data =================\\n\")\n",
    "print(f\"Accuracy of KNN Classifier on Test Data: {accuracy_test*100:.2f}%\\n\")\n",
    "print(f\"Confusion Matrix on Test Data:\")\n",
    "print(conf_matrix_test)\n",
    "print()\n",
    "print(\"Classification Report on Test Data:\")\n",
    "print(report_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
