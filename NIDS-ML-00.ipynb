{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data:  (125973, 42)\n",
      "Shape of the test data:  (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import arff\n",
    "\n",
    "largeDataSet = './data/raw/KDDTrain.arff'\n",
    "smallDataSet = './data/raw/KDDTrain_20Percent.arff'\n",
    "\n",
    "largeTestData = './data/raw/KDDTest.arff'\n",
    "smallTestData = './data/raw/KDDTest-21.arff'\n",
    "\n",
    "# Loading the .arff data format into a pandas dataframe\n",
    "data, meta = arff.loadarff(largeDataSet)\n",
    "test_data, test_meta = arff.loadarff(largeTestData)\n",
    "\n",
    "train = pd.DataFrame(data)\n",
    "test = pd.DataFrame(test_data)\n",
    "\n",
    "print('Shape of the training data: ', train.shape)\n",
    "print('Shape of the test data: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# for feature in categorical_cols:\n",
    "#     plt.figure(figsize=(17, 5)) \n",
    "#     sns.countplot(data=df, x=feature, palette='Set3')\n",
    "#     plt.title(f'Distribution of {feature}')\n",
    "#     plt.xticks(rotation=85)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_outbound_cmds']\n",
      "['num_outbound_cmds']\n",
      "(125973, 42) (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([col for col in train if train[col].nunique() == 1])\n",
    "print([col for col in test if test[col].nunique() == 1])\n",
    "print(train.shape , test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 41) (22544, 41)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = train.drop(columns='num_outbound_cmds')\n",
    "test = test.drop(columns='num_outbound_cmds')\n",
    "print(train.shape , test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 92) (22544, 92)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_categorical = train[train.select_dtypes(include=['object']).columns]\n",
    "test_categorical = test[test.select_dtypes(include=['object']).columns]\n",
    "\n",
    "train_categorical = train_categorical.drop(columns='class')\n",
    "test_categorical = test_categorical.drop(columns='class')\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(train_categorical)\n",
    "\n",
    "train_encoded = encoder.transform(train_categorical)\n",
    "test_encoded = encoder.transform(test_categorical)\n",
    "\n",
    "print(train_encoded.shape , test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 33) (22544, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_numerical = train[train.select_dtypes(include=['float64']).columns]\n",
    "test_numerical = test[test.select_dtypes(include=['float64']).columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_numerical)\n",
    "test_scaled = scaler.transform(test_numerical)\n",
    "\n",
    "print(train_scaled.shape , test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 125) (22544, 125)\n"
     ]
    }
   ],
   "source": [
    "# train_scaled = pd.DataFrame(train_scaled, columns=train_numerical.columns)\n",
    "# test_scaled = pd.DataFrame(test_scaled, columns=test_numerical.columns)\n",
    "\n",
    "# train_encoded = pd.DataFrame(train_encoded.todense())\n",
    "# test_encoded = pd.DataFrame(test_encoded.todense())\n",
    "\n",
    "# processed_train = pd.concat([train_scaled, train_encoded], axis=1)\n",
    "# processed_test = pd.concat([test_scaled, test_encoded], axis=1)\n",
    "\n",
    "# print(processed_train.shape, processed_test.shape)\n",
    "# processed_train.info()\n",
    "\n",
    "\n",
    "# Convert scaled arrays back to DataFrames with original column names\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=train_numerical.columns)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=test_numerical.columns)\n",
    "\n",
    "# Get the feature names for the encoded columns\n",
    "encoded_columns = encoder.get_feature_names_out(input_features=train_categorical.columns)\n",
    "train_encoded = pd.DataFrame(train_encoded.toarray(), columns=encoded_columns)\n",
    "test_encoded = pd.DataFrame(test_encoded.toarray(), columns=encoded_columns)\n",
    "\n",
    "# Concatenate the scaled and encoded DataFrames\n",
    "processed_train = pd.concat([train_scaled, train_encoded], axis=1)\n",
    "processed_test = pd.concat([test_scaled, test_encoded], axis=1)\n",
    "\n",
    "print(processed_train.shape, processed_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of features in train dataset: 125\n",
      "Initial number of features in test dataset: 125\n",
      "Number of features with high correlation in train dataset: 38\n",
      "Number of remaining features in train dataset: 87\n",
      "Number of remaining features in test dataset: 87\n",
      "(125973, 87) (22544, 87)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix for train dataset\n",
    "corr_matrix_train = processed_train.corr(method='pearson')\n",
    "\n",
    "print(\"Initial number of features in train dataset:\", len(corr_matrix_train.columns))\n",
    "\n",
    "# Calculate the correlation matrix for test dataset\n",
    "corr_matrix_test = processed_test.corr(method='pearson')\n",
    "\n",
    "print(\"Initial number of features in test dataset:\", len(corr_matrix_test.columns))\n",
    "\n",
    "# Define the correlation threshold\n",
    "corr_threshold = 0.6\n",
    "\n",
    "# Find highly correlated features for train dataset\n",
    "high_corr_features_train = set()\n",
    "\n",
    "# Iterate through upper triangle of the correlation matrix for train dataset\n",
    "for i in range(len(corr_matrix_train.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix_train.columns)):\n",
    "        if abs(corr_matrix_train.iloc[i, j]) > corr_threshold:\n",
    "            high_corr_features_train.add(corr_matrix_train.columns[i])\n",
    "            high_corr_features_train.add(corr_matrix_train.columns[j])\n",
    "\n",
    "print(\"Number of features with high correlation in train dataset:\", len(high_corr_features_train))\n",
    "\n",
    "# Drop highly correlated features from both train and test datasets\n",
    "processed_train = processed_train.drop(columns=high_corr_features_train)\n",
    "processed_test = processed_test.drop(columns=high_corr_features_train)\n",
    "\n",
    "print(\"Number of remaining features in train dataset:\", len(processed_train.columns))\n",
    "print(\"Number of remaining features in test dataset:\", len(processed_test.columns))\n",
    "\n",
    "print(processed_train.shape, processed_test.shape)\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# sns.heatmap(processed_train.corr(method='pearson'), fmt='.1g', vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', linewidths=3, linecolor='black')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 87) (22544, 87)\n",
      "(125973,) (22544,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train = processed_train.to_numpy()\n",
    "y_train = train['class'].values\n",
    "\n",
    "X_test = processed_test\n",
    "y_test = test['class'].values\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      3\u001b[0m knn_model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m knn_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/bin/BRACU/BRACU-CSE422/Course Project - Network Intrusion Detection using Machine Learning/.venv/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/bin/BRACU/BRACU-CSE422/Course Project - Network Intrusion Detection using Machine Learning/.venv/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:228\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m@_fit_context\u001b[39m(\n\u001b[1;32m    207\u001b[0m     \u001b[39m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    211\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[0;32m~/bin/BRACU/BRACU-CSE422/Course Project - Network Intrusion Detection using Machine Learning/.venv/lib/python3.11/site-packages/sklearn/neighbors/_base.py:480\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m check_classification_targets(y)\n\u001b[1;32m    481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[39m# Using `dtype=np.intp` is necessary since `np.bincount`\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39m# (called in _classification.py) fails when dealing\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m# with a float64 array on 32bit systems.\u001b[39;00m\n",
      "File \u001b[0;32m~/bin/BRACU/BRACU-CSE422/Course Project - Network Intrusion Detection using Machine Learning/.venv/lib/python3.11/site-packages/sklearn/utils/multiclass.py:215\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    207\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m ]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
